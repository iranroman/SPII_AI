{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The K-nearest neighbors algorithm\n",
    "\n",
    "In this notebook you will implement the k-nearest neighbors (KNN) algorithm with k-fold cross validation\n",
    "\n",
    "We will use the Iris dataset\n",
    "\n",
    "Let's remember what we need to write the KNN algorithm\n",
    "\n",
    "* Labeled, multidimensional data (training, and validation set)\n",
    "* A distance (L1 vs L2)\n",
    "* A number of neighbors (must be odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Iris dataset has multiple examples and four features with continuous values.\n",
    "\n",
    "# let's load the iris dataset\n",
    "# your code here\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# We will only use the first two features in the Iris dataset so that we can generate 2D scatter plots\n",
    "X = X[:,:2]\n",
    "\n",
    "# finally, we will convert X and y into numpy arrays\n",
    "import numpy as np\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print('The shape of X is: ', X.shape)\n",
    "print('The shape of y is: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we want to use K-fold cross validation, we must randomly select ~10% of the data as the test set\n",
    "Ntotal = X.shape[0]\n",
    "Ntest = X.shape[0]//10\n",
    "Ntrain = Ntotal - Ntest\n",
    "\n",
    "# generate a list of Ntest random indices, without repetitions, in the range of Ntotal\n",
    "# these indices will be the indices of your test data. Use the function np.random.choice()\n",
    "test_idx = # your code here\n",
    "\n",
    "# separate training and testing data\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "X_train = np.delete(X, test_idx, axis=0)\n",
    "y_train = np.delete(y, test_idx)\n",
    "\n",
    "print('The shape of X_test is: ', X_test.shape)\n",
    "print('The shape of y_test is: ', y_test.shape)\n",
    "print('The shape of X_train is: ', X_train.shape)\n",
    "print('The shape of y_train is: ', y_train.shape)\n",
    "\n",
    "# We will forget about the test data for now. We will only use it at the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will split the training data into five folds. We will store each of the folds \n",
    "# as an element of a python list. We will have a list for X and another list for y\n",
    "\n",
    "# we want to randomly split the training data into 5 chunks of equal size\n",
    "# let's first generate random integers without repetition in the range of Ntrain\n",
    "train_idx = # your code here\n",
    "\n",
    "# now let's iterate over the training data to obtain the \n",
    "# 5 folds\n",
    "Nfolds = 5\n",
    "fold_size = Ntrain//Nfolds\n",
    "X_folds = [] # this will be a list of 5 numpy arrays with datapoints\n",
    "y_folds = [] # this will be a list of 5 numpy arrays with the corresponding labels\n",
    "for i in range(Nfolds):\n",
    "    \n",
    "    X_folds # your code here\n",
    "    y_folds # your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use k-fold cross validation to find the best k value for the KNN algorithm\n",
    "# we will test the following K values\n",
    "\n",
    "Ks = [1, 3, 5, 11, 21, 51, 101]: # you can try other k values if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will also need the distance function\n",
    "\n",
    "def L1_norm(X,a):\n",
    "    '''\n",
    "    X is a numpy matrix where each row is a 2D training datapoint.\n",
    "    a is a numpy vector representing a 2D validation datapoint\n",
    "    \n",
    "    Write a function to calculate the norm between X and a\n",
    "    using np.abs, and np.sum(B,axis=1) where the axis=1 argument\n",
    "    limits the sum operation to be independently carried out for\n",
    "    the dimensions of each row in the matrix B\n",
    "    '''\n",
    "\n",
    "    norm = # your code here\n",
    "\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have everything we need. Now we can write the KNN algorithm with k-fold cross validation. \n",
    "\n",
    "The algorithm is:\n",
    "* For all k-nearest neighbor values that we want to try\n",
    "    * For all possible k-fold splits of training and validation data\n",
    "        * Store the features and classes of the training data\n",
    "        * For each validation point:\n",
    "            * Compute the distance between the validation datapoint and all the training datapoints.\n",
    "            * Find the top k nearest training neighbors\n",
    "            * The category of the validation datapoint is presumed to be the most common category among the k nearest training neighbors.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import the statistics library to use the mode function\n",
    "from scipy import stats\n",
    "\n",
    "# we will have three nested for loops here:\n",
    "\n",
    "all_knn_fold_acc = []\n",
    "for k in Ks: # for all the k values that we want to test\n",
    "    all_fold_acc = []\n",
    "    for ifold in range(Nfolds): # for all the possible validation folds \n",
    "        \n",
    "        # first, convert the folds into training and validation sets\n",
    "        X_vl = # your code here\n",
    "        y_vl = # your code here\n",
    "        X_tr = # your code here. hint: use list comprehension in this line\n",
    "        y_tr = # your code here. hint: use list comprehension in this line\n",
    "        # because you used list comprehension in the two lines above,\n",
    "        # convert the training set into a numpy array:\n",
    "        X_tr = np.vstack(X_tr) # do not change this line\n",
    "        y_tr = np.hstack(y_tr) # do not change this line\n",
    "        \n",
    "        KNN = []\n",
    "        for x_vl in X_vl: # for all datapoints in the validation set\n",
    "            all_distances = # your code here. hint: use your L1 function\n",
    "            sorted_distances = sorted([(d,i) for i, d in enumerate(all_distances)])\n",
    "            K_close_examps = sorted_distances[:k]\n",
    "\n",
    "            K_close_categories = []\n",
    "            for examp in K_close_examps:\n",
    "                \n",
    "                K_close_categories.append(y_tr[examp[1]])\n",
    "                \n",
    "            KNN.append(K_close_categories)\n",
    "\n",
    "        correct_count = 0\n",
    "        for iknn, knn in enumerate(KNN):\n",
    "            \n",
    "            if stats.mode(knn)[0] == y_vl[iknn]:\n",
    "                correct_count += 1\n",
    "        all_fold_acc.append(correct_count/len(y_vl))\n",
    "    all_knn_fold_acc.append(all_fold_acc)\n",
    "    \n",
    "# only write code where you see 'your code here'. Everything else will work on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell generates a plot that will let you see what the best k\n",
    "# for your model is\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(Ks,all_knn_fold_acc,'ok')\n",
    "plt.errorbar(Ks,np.mean(all_knn_fold_acc,axis=1),np.std(all_knn_fold_acc,axis=1))\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find which value of k gave you the best results\n",
    "# use the entire training set to create your model\n",
    "# and test the performance with the test set that we\n",
    "# separated at the top\n",
    "\n",
    "# your code here\n",
    "\n",
    "# What is the test accuracy that you obtained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done, try the following:\n",
    "* Use the L2 norm instead of L1 \n",
    "* Use another set of 2 features from the Iris dataset\n",
    "* Use more than two features. Start using 3 features and generate 3D plots.\n",
    "\n",
    "Do you understand what is happenning in all the lines of code that were prodivided to you and you did not have to write?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
